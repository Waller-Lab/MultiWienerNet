<!DOCTYPE html>
<html lang="en">
<head>

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<title>Deep learning for fast spatially-varying deconvolution</title>

	<!-- Bootstrap -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

	<link href="styles/minimal.css" rel="stylesheet">
</head>

<body>

<!-- Navigation bar -->
<nav class="navbar navbar-default navbar-fixed-top">
	<div class="container-nav">
		<div class="container-fluid">
    		<ul class="nav navbar-nav">
      			<li class="nav-item active"><a href="index.html">Home</a></li>
      			<li class="nav-item"><a href="gallery.html">Gallery</a></li>
				<li class="nav-item"><a href="https://github.com/Waller-Lab/MultiWienerNet">Code</a></li>
				<li class="nav-item"><a href="https://doi.org/10.1364/OPTICA.442438">Paper</a></li>
    		</ul>
      	</div>
    </div>
</nav>

<div class="container">

	<div class="row">
		<h1><b>Deep learning for fast spatially-varying deconvolution</b></h1>
		<h5><b><a href="https://kyrollosyanny.com/">Kyrollos Yanny*</a>, <a href="https://kristinamonakhova.com/">Kristina Monakhova*</a>, <a href = "https://www.linkedin.com/in/richard-shuai/">Richard Shuai</a>, and <a href="http://www.laurawaller.com/">Laura Waller</a></b></h5>
		<br />
		<img class="center" src="resources/overview.jpg" style="width:700px">
	</div>

	<div class="row">
		<h3><b>Abstract</b></h3>
		<p>Deconvolution can be used to obtain sharp images or volumes from blurry
			or encoded measurements in imaging systems. Given knowledge of the
			system’s point spread function (PSF) over the field-of-view, a
			reconstruction algorithm can be used to recover a clear image or volume.
			Most deconvolution algorithms assume shift-invariance; however, in
			realistic systems, the PSF varies laterally and axially across the
			field-of-view, due to aberrations or design. Shift-varying models can be
			used, but are often slow and computationally intensive. In this work, we
			propose a deep learning-based approach that leverages knowledge about the
			system’s spatially-varying PSFs for fast 2D and 3D reconstructions. Our
			approach, termed MultiWienerNet, uses multiple differentiable Wiener
			filters paired with a convolutional neural network to incorporate
			spatial-variance. Trained using simulated data and tested on experimental
			data, our approach offers a 625 − 1600× speed-up compared to iterative
			methods with a spatially-varying model, and outperforms existing
			deep-learning based methods that assume shift invariance.</p>
		</div>

		<div class="row">
			<h3><b>Resources</b></h3>
			<ul>
				<li>Open source code: <b><a href="https://github.com/Waller-Lab/MultiWienerNet">here</a></b></li>
				<li>Paper in Optica: <b><a href="https://doi.org/10.1364/OPTICA.442438">here</a></b></li>
				<li>Miniscope3D <b><a href="https://github.com/Waller-Lab/Miniscope3D">code</a></b> and <b><a href="https://waller-lab.github.io/Miniscope3D/">project page</a></b> </li>
				<!-- <li><b><a href="gallery.html">Gallery</a></b> of reconstructions</li>-->
			</ul>
		</div>

		<div class="row">
			<h2><b>Method overview</b></h2>
			<h3><b>Calibration</b></h3>
			<p>We need to calibrate the network for each new microscope or imaging
				system. To calibrate, we scan a bead across the field of view of the
				microscope and capture point spread functions (PSFs).
		</p>
			<img class="center" src="resources/CalibrationGIF.gif" style="width:400px">

		</div>
		<div class="row">
		<h3> <b>Dataset creation</b> </h3>
		<p>
		With our calibrated PSFs, we can create a forward model for our microscope
		and use this to generate training data for our network.</p>
		<img class="center" src="resources/dataset_gif.gif" style="width:400px">

		</div>
		<div class="row">
		<h3> <b>Training </b></h3>
		<p>
		We initialize our network filters with a subset of our measured PSFs. The network
		performs a Wiener deconvolution step for each filter, then combines the
		intermediate images into the final deconvoled image. The parameters of the
		network are updated to minimize the loss between the deconvolved image and
		the ground truth image over the entire dataset.</p>

		<img class="center" src="resources/training_gif.gif" style="width:650px">

		</div>
		<div class="row">
		<h3> <b>Fast deconvolutions </b></h3>
		<p>
		After training, we can use our deconvolution network on real data! </p>
		<img class="center" src="resources/deconv_gif.gif" style="width:400px">

		<p>
		Our method works for 2D deconvolutions, as well as compressive 3D
		deconvolutions in which a 3D volume is recovered from a 2D measurement.</p>
		</div>



<!--
	<div class="row">
		<h3><b>Overview Video</b></h3>
		<iframe width="660" height="415"
src="https://www.youtube.com/embed/ReH0x_W3glM">
</iframe>
</div>-->





</body>
</html>
